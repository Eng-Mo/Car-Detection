{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.feature import hog\n",
    "import glob\n",
    "import cv2\n",
    "import pdb\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data function used combination data from GTI and KITTI\n",
    "def loadData():\n",
    "    images=glob.glob('./dataset/vehicles/GTI_Far/image*.png')\n",
    "    train_car=[]    \n",
    "    train_not_car=[]\n",
    "#     all data was read using cv2.imread() to avoid diffrent imge format\n",
    "\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)    \n",
    "        train_car.append(img)\n",
    "        \n",
    "    images=glob.glob('./dataset/vehicles/GTI_Left/image*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)  \n",
    "        train_car.append(img)\n",
    "        \n",
    "    images=glob.glob('./dataset/vehicles/GTI_Right/image*.png')\n",
    "\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_car.append(img)\n",
    "        \n",
    "\n",
    "    images=glob.glob('./dataset/vehicles/MiddleClose/image*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_car.append(img)\n",
    "        \n",
    "\n",
    "    images=glob.glob('./dataset/vehicles/KITTI_extracted/*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_car.append(img)\n",
    "        \n",
    "\n",
    "\n",
    "    images=glob.glob('./dataset/non-vehicles/GTI/image*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_not_car.append(img)\n",
    "        \n",
    "\n",
    "    images=glob.glob('./dataset/non-vehicles/Extras/extra*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_not_car.append(img)\n",
    "      \n",
    "\n",
    "   \n",
    "    return (train_car,train_not_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# this function to draw color space in 3D\n",
    "def plot3d(pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32,32)):\n",
    "    # binning spatial feature with size (16X16) to reduce computation\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    \n",
    "    return np.hstack((color1, color2, color3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def HistofClolor(img,nbins=32, bins_range=(0, 255)):\n",
    "#     Color feature histogram\n",
    "#     hist_features=[]\n",
    "    yhist=np.histogram(img[:,:,0], bins=32, range=(0, 255))\n",
    "    crhist=np.histogram(img[:,:,1], bins=32, range=(0, 255))\n",
    "    cbhist=np.histogram(img[:,:,2], bins=32, range=(0, 255))\n",
    "    hist_features= np.concatenate((yhist[0], crhist[0], cbhist[0])) #concatinate color features    \n",
    "    return hist_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img_channel, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=False,ch=3):\n",
    "    \n",
    "#     extracting Hog feature from gray scal image (for single channel) to reduce computation\n",
    "# the commetted lines for extracting Hog for 3 three channels\n",
    "    features_data = []\n",
    "    if  ch==3:\n",
    "#         img=cv2.cvtColor(imgo,cv2.COLOR_RGB2GRAY)  #conver to gray\n",
    "        ch_0=imgo[:,:,0]\n",
    "        ch_1=imgo[:,:,1]\n",
    "        ch_2=imgo[:,:,2]\n",
    "        \n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "\n",
    "        # Use skimage.hog() to get both features and a visualization\n",
    "        features_0 = hog(ch_0, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell)\n",
    "                                  , cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "#         plt.title('sample HOG')\n",
    "#         plt.imshow(imagehog)\n",
    "#         plt.savefig('./output_images/hog_sample.png')\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "        features_1 = hog(ch_1, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell)\n",
    "                                  , cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "#         plt.imshow(imagehog)\n",
    "#         plt.show()\n",
    "# #         \n",
    "\n",
    "        features_2 = hog(ch_2, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell)\n",
    "                                  , cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "#         plt.imshow(imagehog)\n",
    "#         plt.show()\n",
    "        \n",
    "#         features_0=features_0.reshape(-1)  # reshape feature vector\n",
    "#         features_1=features_1.reshape(-1)\n",
    "#         features_2=features_2.reshape(-1)\n",
    "        features_data.append(features_0)\n",
    "        features_data.append(features_1)\n",
    "        features_data.append(features_2)\n",
    "        \n",
    "\n",
    "#         features_data.append(np.hstack((features_0,features_1,features_2)))\n",
    "#         features_data = np.ravel(features_data) \n",
    "#         features_data.append(features_0)  # appending Hog features\n",
    "\n",
    "        \n",
    "        return features_data\n",
    "\n",
    "\n",
    "    else:\n",
    "        \n",
    "        features_0= hog(img_channel, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell)\n",
    "                                  , cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "     \n",
    "\n",
    "        # Use skimage.hog() to get features only\n",
    "                \n",
    "        return features_0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractFeature(data, spatial_size,hist_bins,orient,pix_per_cell,cell_per_block,hog_ch):\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    file_features=[]  # concatinated features per image\n",
    "  \n",
    "    features=[]   # all features data\n",
    "    feature_hog=[]  #Hog features\n",
    "#     HSV_data=[]\n",
    "    count=0\n",
    "    for i in data:\n",
    "#         plt.imshow(i)\n",
    "#         plt.show()\n",
    "       \n",
    "        \n",
    "              \n",
    "        \n",
    "        img_YCrCb = cv2.cvtColor(i, cv2.COLOR_RGB2YCrCb)  #convert image to YCrCb\n",
    "        \n",
    "        \n",
    " #         pdb.set_trace()\n",
    "        spatial_features=bin_spatial(img_YCrCb, size=spatial_size)  #extract spatial features\n",
    "#         pdb.set_trace()\n",
    "        hist_features=HistofClolor(img_YCrCb,nbins=hist_bins, bins_range=(0, 255))  #extract histogram features\n",
    "        if hog_ch==3:\n",
    "            \n",
    "            feature_hog0, feature_hog1, feature_hog2=get_hog_features(img_YCrCb, orient,                             #extract Hog features\n",
    "                            pix_per_cell, cell_per_block, \n",
    "                            vis=False, feature_vec=False,ch=hog_ch)\n",
    "        else:\n",
    "            gray=cv2.cvtColor(i,cv2.COLOR_RGB2GRAY)\n",
    "            feature_hog=get_hog_features(gray, orient,                             #extract Hog features\n",
    "                            pix_per_cell, cell_per_block, \n",
    "                            vis=False, feature_vec=False,ch=hog_ch)\n",
    "            \n",
    "        \n",
    "        feature_hog=np.reshape(feature_hog,-1)             #reshape Hog features\n",
    "#         print(spatial_features.shape)\n",
    "#         print(feature_hog.shape)\n",
    "#         print(hist_features.shape)\n",
    "        file_features=np.concatenate((spatial_features, \n",
    "                                      hist_features,feature_hog),0)  #concatenate features image\n",
    "        \n",
    "        \n",
    "        features.append(file_features)  #append features image\n",
    "        count+=1\n",
    "    \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featuresCalc(car, not_car,spatial_size,hist_bins,orient,pix_per_cell,cell_per_block,hog_ch):\n",
    "    \n",
    "    car_features=extractFeature( car,spatial_size,hist_bins,orient,pix_per_cell,cell_per_block,hog_ch)\n",
    "        #pdb.set_trace()\n",
    "    not_car_features=extractFeature(not_car,spatial_size,hist_bins,orient,pix_per_cell,cell_per_block,hog_ch)\n",
    "    \n",
    "    return car_features,not_car_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainClf(features_c,features_nc,spatial_size,hist_bins,orient,pix_per_cell,cell_per_block,hog_ch):\n",
    "  \n",
    "\n",
    "    # Create an array stack, NOTE: StandardScaler() expects np.float64\n",
    "\n",
    "    X = np.vstack((features_c, features_nc)).astype(np.float64)  # stack features \n",
    "\n",
    "    from sklearn.preprocessing import  StandardScaler\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler(copy = False).fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)    #Normalise data\n",
    "    spatial=32\n",
    "    histbin=32\n",
    "    y = np.hstack((np.ones(len(features_c)), np.zeros(len(features_nc))))   #create lable array\n",
    "    rand_state = np.random.randint(0, 1000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(                           #split data to train and test 40%\n",
    "        scaled_X, y, test_size=0.3, random_state=rand_state)\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    print('Using spatial binning of:',spatial,\n",
    "        'and', histbin,'histogram bins')\n",
    "    print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "    parameters = {'kernel':['linear'], 'C':[.001]}\n",
    "    # svc = svm.SVC()\n",
    "    # gs = GridSearchCV(svc, parameters,cv=2,n_jobs=4,verbose=3,)         #GridsearchCV was very slow\n",
    "    # gs.fit(X_train, y_train)\n",
    "\n",
    "    # aGrid = aML_GS.GridSearchCV( aClassifierOBJECT, param_grid = aGrid_of_parameters,\n",
    "    #                             cv = cv, n_jobs = n_JobsOnMultiCpuCores, verbose = 5 )\n",
    "\n",
    "\n",
    "    # # Use a linear SVC \n",
    "    svc = LinearSVC(C=.01,dual=False)     #create classifier\n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)     #fit train data\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))  #predict test data\n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    n_predict = len(X_test)\n",
    "    # print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "    # print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "\n",
    "    import pickle\n",
    "    # now you can save it to a file\n",
    "\n",
    "    pickle_file = 'clf.pkl'\n",
    "    print('Saving data to pickle file...')\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                'svc':svc, \n",
    "                'X_scaler': X_scaler,\n",
    "                'spatial_size': spatial_size,\n",
    "                'hist_bins': hist_bins,\n",
    "                'orient': orient,\n",
    "                'pix_per_cell': pix_per_cell,\n",
    "                'cell_per_block': cell_per_block,\n",
    "                'hog_channel': hog_ch,\n",
    "            },\n",
    "\n",
    "             f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processData():\n",
    "    \n",
    "    #     Features parameter\n",
    "\n",
    "    spatial_size=(32,32)  #spatial binned size\n",
    "    hist_bins=32    \n",
    "    orient = 9\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    hog_ch = 1\n",
    "\n",
    "\n",
    "    car_, not_car_=loadData()\n",
    "    \n",
    "    carfeatures, notcar_features=featuresCalc(car_,not_car_,spatial_size,hist_bins,orient,pix_per_cell\n",
    "                                              ,cell_per_block, hog_ch)\n",
    "    trainClf(carfeatures,notcar_features,spatial_size,hist_bins,orient,pix_per_cell,cell_per_block,hog_ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using spatial binning of: 32 and 32 histogram bins\n",
      "Feature vector length: 4932\n",
      "10.51 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.986\n",
      "0.0 Seconds to predict 5203 labels with SVC\n",
      "Saving data to pickle file...\n"
     ]
    }
   ],
   "source": [
    "processData()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
