{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.feature import hog\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn\n",
    "import glob\n",
    "import cv2\n",
    "import pdb\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data function used combination data from GTI and KITTI\n",
    "def loadData():\n",
    "    images=glob.glob('./vehicles/vehicles/GTI_Far/image*.png')\n",
    "    train_car=[]    \n",
    "    train_not_car=[]\n",
    "#     all data was read using cv2.imread() to avoid diffrent imge format\n",
    "\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)    \n",
    "        train_car.append(img)\n",
    "        \n",
    "    images=glob.glob('./vehicles/vehicles/GTI_Left/image*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)  \n",
    "        train_car.append(img)\n",
    "        \n",
    "    images=glob.glob('./vehicles/vehicles/GTI_Right/image*.png')\n",
    "\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_car.append(img)\n",
    "        \n",
    "\n",
    "    images=glob.glob('./vehicles/vehicles/MiddleClose/image*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_car.append(img)\n",
    "        \n",
    "\n",
    "    images=glob.glob('./vehicles/vehicles/KITTI_extracted/*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_car.append(img)\n",
    "        \n",
    "\n",
    "\n",
    "    images=glob.glob('./non-vehicles/non-vehicles/GTI/image*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_not_car.append(img)\n",
    "        \n",
    "\n",
    "    images=glob.glob('./non-vehicles/non-vehicles/Extras/extra*.png')\n",
    "    for fname in images:\n",
    "        img=cv2.imread(fname)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        train_not_car.append(img)\n",
    "      \n",
    "\n",
    "   \n",
    "    return (train_car,train_not_car)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# this function to draw color space in 3D\n",
    "def plot3d(pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(16,16)):\n",
    "    # binning spatial feature with size (16X16) to reduce computation\n",
    "    features=[]    \n",
    "    features .append(cv2.resize(img,size).ravel()) \n",
    "    return features\n",
    "    # Return the feature vector\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def HistofClolor(img,nbins=32, bins_range=(0, 256)):\n",
    "#     Color feature histogram\n",
    "    hist_features=[]\n",
    "    hhist=np.histogram(img[:,:,0], bins=32, range=(0, 255))\n",
    "    shist=np.histogram(img[:,:,1], bins=32, range=(0, 255))\n",
    "    vhist=np.histogram(img[:,:,2], bins=32, range=(0, 255))\n",
    "    hist_features.append(np.concatenate((hhist[0], shist[0], vhist[0]))) #concatinate color features    \n",
    "    return hist_features   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(imgo, orient, pix_per_cell, cell_per_block, vis=True, feature_vec=False):\n",
    "    \n",
    "#     extracting Hog feature from gray scal image (for single channel) to reduce computation\n",
    "# the commetted lines for extracting Hog for 3 three channels\n",
    "    features_data = []\n",
    "    if vis == True:\n",
    "        img=cv2.cvtColor(imgo,cv2.COLOR_RGB2GRAY)  #conver to gray\n",
    "#         ch_0=img[:,:,0]\n",
    "#         ch_1=img[:,:,1]\n",
    "#         ch_2=img[:,:,2]\n",
    "        \n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "\n",
    "        # Use skimage.hog() to get both features and a visualization\n",
    "        features_0, imagehog = hog(img, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell)\n",
    "                                  , cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  visualise=True, feature_vector=False,transform_sqrt=True )\n",
    "#         plt.title('sample HOG')\n",
    "#         plt.imshow(imagehog)\n",
    "#         plt.savefig('./output_images/hog_sample.png')\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "#         features_1, imagehog = hog(ch_1, orientations=orient,\n",
    "#                                   pixels_per_cell=(pix_per_cell, pix_per_cell)\n",
    "#                                   , cells_per_block=(cell_per_block, cell_per_block),\n",
    "#                                   visualise=True, feature_vector=False)\n",
    "# #         plt.imshow(imagehog)\n",
    "# #         plt.show()\n",
    "# #         \n",
    "\n",
    "#         features_2, imagehog = hog(ch_2, orientations=orient,\n",
    "#                                   pixels_per_cell=(pix_per_cell, pix_per_cell)\n",
    "#                                   , cells_per_block=(cell_per_block, cell_per_block),\n",
    "#                                   visualise=True, feature_vector=False)\n",
    "#         plt.imshow(imagehog)\n",
    "#         plt.show()\n",
    "        \n",
    "        features_0=features_0.reshape(-1)  # reshape feature vector\n",
    "#         features_1=features_1.reshape(-1)\n",
    "#         features_2=features_2.reshape(-1)\n",
    "        \n",
    "\n",
    "#         features_data.append(np.concatenate((features_0,features_1,features_2)))\n",
    "        features_data.append(features_0)  # appending Hog features\n",
    "\n",
    "        \n",
    "        return features_data\n",
    "\n",
    "\n",
    "    else:      \n",
    "        # Use skimage.hog() to get features only\n",
    "        features = [] # Remove this line\n",
    "        return features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all features extraction\n",
    "\n",
    "def extractFeature(data, color_space='HSV', size=(32, 32)):\n",
    "\n",
    "#     Hog parameter\n",
    "    orient = 9\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 4\n",
    "    \n",
    "    \n",
    "    file_features=[]  # concatinated features per image\n",
    "  \n",
    "    features=[]   # all features data\n",
    "    feature_hog=[]  #Hog features\n",
    "    spatial_size=(16,16)  #spatial binned size\n",
    "#     HSV_data=[]\n",
    "    count=0\n",
    "    for i in data:\n",
    "       \n",
    "        \n",
    "        img_YCrCb = cv2.cvtColor(i, cv2.COLOR_RGB2YCrCb)  #convert image to YCrCb\n",
    " #         pdb.set_trace()\n",
    "        spatial_features=bin_spatial(img_YCrCb, size=spatial_size)  #extract spatial features\n",
    "#         pdb.set_trace()\n",
    "        hist_features=HistofClolor(img_YCrCb,nbins=32, bins_range=(0, 256))  #extract histogram features\n",
    "        feature_hog=get_hog_features(i, orient,                             #extract Hog features\n",
    "                        pix_per_cell, cell_per_block, \n",
    "                        vis=True, feature_vec=False)\n",
    "        feature_hog=np.reshape(feature_hog,(1,-1))               #reshape Hog features\n",
    "        file_features=np.concatenate((spatial_features, \n",
    "                                      hist_features,feature_hog),1)  #concatenate features image\n",
    "        features.append(np.concatenate(file_features))  #append features image\n",
    "    \n",
    "    \n",
    "    return features\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "car,not_cor=loadData()  # load data\n",
    "sc=car[0:4000]          #select 4000 car sample\n",
    "snc=not_cor[0:4000]     #select 4000 not car sample\n",
    "# plt.title('sample car')\n",
    "# plt.imshow(sc[0])\n",
    "# plt.savefig('./output_images/sample_car.png')\n",
    "# plt.show()\n",
    "# plt.title('sample not car')\n",
    "# plt.imshow(snc[0])\n",
    "# plt.savefig('./output_images/sample_not_car.png')\n",
    "# plt.show()\n",
    "#pdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "car_features=extractFeature(                     #extract car features\n",
    "    sc, color_space='YCrCb', size=(32, 32))\n",
    "#pdb.set_trace()\n",
    "not_car_features=extractFeature(                 #extract not car features\n",
    "    snc, color_space='YCrCb', size=(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using spatial binning of: 32 and 32 histogram bins\n",
      "Feature vector length: 4464\n",
      "1.83 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9772\n",
      "9e-05 Seconds to predict 3200 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# Create an array stack, NOTE: StandardScaler() expects np.float64\n",
    "\n",
    "X = np.vstack((car_features, not_car_features)).astype(np.float64)  # stack features \n",
    "\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler(copy = False).fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)    #Normalise data\n",
    "spatial=32\n",
    "histbin=32\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))   #create lable array\n",
    "rand_state = np.random.randint(0, 1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(                           #split data to train and test 40%\n",
    "    scaled_X, y, test_size=0.4, random_state=rand_state)\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "print('Using spatial binning of:',spatial,\n",
    "    'and', histbin,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "parameters = {'kernel':['linear'], 'C':[100]}\n",
    "# svc = svm.SVC()\n",
    "# gs = GridSearchCV(svc, parameters,cv=2,n_jobs=4,verbose=3,)         #GridsearchCV was very slow\n",
    "# gs.fit(X_train, y_train)\n",
    "\n",
    "# aGrid = aML_GS.GridSearchCV( aClassifierOBJECT, param_grid = aGrid_of_parameters,\n",
    "#                             cv = cv, n_jobs = n_JobsOnMultiCpuCores, verbose = 5 )\n",
    "\n",
    "\n",
    "# # Use a linear SVC \n",
    "svc = LinearSVC()     #create classifier\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)     #fit train data\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))  #predict test data\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = len(X_test)\n",
    "# print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "# print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    draw_img = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(draw_img, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windowex(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "#     pdb.set_trace()\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    #print(window_list[0].shape)\n",
    "    #finalimage=draw_boxes(img,window_list)\n",
    "    # Return the list of windows\n",
    "#     print (len(window_list))\n",
    "    return window_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  StandardScaler\n",
    "def searchwindow(img,ws):    #predict windows\n",
    "\n",
    "    on_windows=[]\n",
    " \n",
    "    li=[]\n",
    "    for window in ws:\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], \n",
    "                                  window[0][0]:window[1][0]], (64, 64))   #extract window     \n",
    "        li.append(test_img)        #I send window in list as feature extraction funtion accept list of images\n",
    "        features=extractFeature(li, color_space='RGB', size=(32, 32))    #extract features window\n",
    "#         print(features[0].shape)\n",
    "\n",
    "        test_features = X_scaler.transform(np.array(features).reshape(1, -1))  #normalise features\n",
    "        prediction = svc.predict(test_features)                                #predict window\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)          #if car append in on windows\n",
    "        del li[:]\n",
    "\n",
    "    return on_windows\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interestT(img):\n",
    "    \n",
    "    \n",
    "    mask = np.zeros(img.shape, dtype=np.uint8) #mask image\n",
    "    roi_corners = np.array([[(650,680), (1280,680), (1280,400),(650,400)]], \n",
    "                           dtype=np.int32) # vertisies seted to form trapezoidal scene\n",
    "    channel_count = 1#img.shape[2]  # image channels\n",
    "    ignore_mask_color = (255,)*channel_count\n",
    "    cv2.fillPoly(mask, roi_corners, ignore_mask_color)   \n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findcont(img):   #find contours in heat map and dilate them to group closed high heats\n",
    "    imagebg=cv2.imread('./test_images/test2.jpg')\n",
    "#     plt.imshow(imagebg)\n",
    "#     plt.show()\n",
    "    graybg=cv2.cvtColor(imagebg,cv2.COLOR_BGR2GRAY)\n",
    "    grayf=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    roibg=region_of_interestT(graybg)\n",
    "    roif=region_of_interestT(grayf)\n",
    "    \n",
    "    \n",
    "    diff=cv2.subtract(roif,roibg)\n",
    "    diff=np.asarray(diff,dtype=np.uint8)\n",
    "\n",
    "    ret,thresh1 = cv2.threshold(im,20,255,cv2.THRESH_BINARY)\n",
    "#     plt.imshow(diff,cmap= 'gray')\n",
    "#     plt.show()\n",
    "    windows=[]       \n",
    "   \n",
    "    im2, cnts, hierarchy = cv2.findContours(diff,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #find contours\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "    cari = None\n",
    "    \n",
    "    for c in cnts:              #obtain four point window to be drawn       \n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "#         cv2.rectangle(img, (x-20,y-20), (x+w,y+h), (255, 0, 0), 2)\n",
    "        w=((x,y),(x+w,y+h))\n",
    "        windows.append(w)\n",
    "\n",
    "    return windows    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.VideoClip import VideoClip\n",
    "import moviepy\n",
    "import matplotlib as mpimg\n",
    "import time\n",
    "from moviepy.Clip import Clip\n",
    "from scipy.ndimage.measurements import label\n",
    "from Lane import *\n",
    "import scipy.misc\n",
    "\n",
    "\n",
    "\n",
    "clip = VideoFileClip('project_video.mp4') # Read clip\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')      #OpenCv writing file\n",
    "out = cv2.VideoWriter('out_video_c.avi',fourcc, 15.0, (640, 360)) # intialise output file\n",
    "\n",
    "frameClibration= clip.get_frame(0)\n",
    "\n",
    "im=scipy.misc.imresize(frameClibration, (180, 320,3))\n",
    "\n",
    "\n",
    "#im=scipy.misc.imresize(rdist, (180, 320,3))\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "d=0      # Frame number\n",
    "# hot_windows=[]\n",
    "for frame in clip.iter_frames(dtype=np.uint8):\n",
    "    \n",
    "        \n",
    "    imageX=frame\n",
    "\n",
    "    heat = np.zeros_like(frame[:,:,0]).astype(np.float) # create heat map\n",
    "    t=time.time()\n",
    "\n",
    "#extract multiscale windows\n",
    "    w=findcont(frame)\n",
    "    \n",
    "\n",
    "    hot_windows=searchwindow(imageX,w)\n",
    "\n",
    "    \n",
    "\n",
    " ##############################################\n",
    "    heat = add_heat(heat,hot_windows)\n",
    "\n",
    "#         Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,4)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "#         w=findcont(heatmap)     # other method for group closed hot peaks  \n",
    "    labels = label(heatmap)\n",
    "    draw_img2=draw_boxes(np.copy(frame),hot_windows)\n",
    "\n",
    "#     fig = plt.figure()\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(draw_img2)\n",
    "#     plt.title('Car Positions2')\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(heatmap, cmap='hot')\n",
    "#     plt.title('Heat Map')\n",
    "#     fig.tight_layout()\n",
    "#     plt.savefig('./output_images/Detected_cars.png')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    t2 = time.time()\n",
    "    tf=t2-t\n",
    "    draw_img2=cv2.putText(draw_img2,'time per frame: %.1f m'%tf,(50,200),\n",
    "                   font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "#     plt.imshow(final_image)\n",
    "# #     plt.savefig('./output_images/result.png')\n",
    "#     plt.show()\n",
    "\n",
    "    f=cv2.resize(draw_img2,(640,360))    #resize frame to reduce video file size \n",
    "\n",
    "    out.write(f)\n",
    "\n",
    "\n",
    "    print('Process time per frame',d,':..',round(t2-t, 5))\n",
    "#     print (d)\n",
    "    d=d+1\n",
    "out.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os, sys\n",
    "import moviepy\n",
    "clip_out='out_video22222_Copy1.avi'\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"1280\" height=\"720\" controls>\n",
    "  <source src=\"{0}\" type=\"video/avi\">\n",
    "</video>\n",
    "\"\"\".format(clip_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image=cv2.imread('./test_images/test1.jpg')\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "imageX=image\n",
    "heat = np.zeros_like(image[:,:,0]).astype(np.float) # create heat map\n",
    "t=time.time()\n",
    "\n",
    "#extract multiscale windows\n",
    "windows=windowex(imageX,x_start_stop=[800, None], y_start_stop=[400, 550]  #extract windows \n",
    "                , xy_window=(90, 90), xy_overlap=(0.8,0.8))\n",
    "\n",
    "hot_windows=searchwindow(imageX,windows)\n",
    "\n",
    "windows=windowex(imageX,x_start_stop=[650, None], y_start_stop=[400, 680]   #extract windows\n",
    "                        , xy_window=(128, 128), xy_overlap=(0.2,0.2))\n",
    "\n",
    "hot_windows.extend(searchwindow(imageX,windows))\n",
    "\n",
    "##############################################\n",
    "heat = add_heat(heat,hot_windows)\n",
    "\n",
    "#         Apply threshold to help remove false positives\n",
    "heat = apply_threshold(heat,3)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "heatmap = np.clip(heat, 0, 255)\n",
    "labels = label(heatmap)\n",
    "\n",
    "w=findcont(heatmap)     #group closed hot peaks\n",
    "labels = label(heatmap)\n",
    "draw_img2=draw_labeled_bboxes(np.copy(image),labels)    #draw windows\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title('Sample Detection & Heatmap')\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img2)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "fig.tight_layout()\n",
    "plt.savefig('./output_images/Detected_cars_1.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
